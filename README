This project runs a MonteCarlo simulation of PLS as a streaming MapReduce job.

MapReduce is an algorithm that divides work in a computing cluster. One
computing node acts as a master and runs the mapper, which takes a problem as an
input file and divides it into smaller subtasks that can be run in parallel.
These subtasks are then run on separate nodes that run the reducer script.

See also http://labs.google.com/papers/mapreduce.html

This set of script takes a text file that contains information about population models, tested models, and simulation parameters. These are divided in the
mapper and passed on to the reducers that will run the jobs.


The simulation can be executed either by running main.R, which runs the simulation as a single thread run, or by uploading the files to Amazon cloud and running the simulation as a streaming job in Elastic MapReduce. The input file needs to be prepared on a local computer.

For an example of how to run R in Amazon cloud, see the following links.

Content of the files

input.txt: A text file that contains a list of the replication numbers that will
be executed. 
main.R: The main file that will run the MapReduce job in a single thread locally. The job runs for a long time, so this is only for testing.
map.R: Map executable
reduce.R: Reduce executable
functions.R: Functions to that are needed for the simulation
parameters.R: Simulation parameters
prepare.R: A file that creates an input file that the MapReduce algorithm processes.
combine.R: Reads in the output from reducers, combines these, and stores the resulting R objects on disk
report.R: Reads the combined output and gnerates tables and figures based on the input.